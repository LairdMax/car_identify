{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,shutil,sys\n",
    "sys.path.append('/data/py/lib/') \n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.applications import VGG16\n",
    "from keras.applications import xception\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "import time\n",
    "original_dataset_dir='/data/keras/download/qiche/all'\n",
    "base_dir='/data/keras/download/qiche'\n",
    "train_dir=os.path.join(base_dir,'train')\n",
    "validation_dir=os.path.join(base_dir,'validation')\n",
    "test_dir=os.path.join(base_dir,'test')\n",
    "mod_names=[\"速腾\",\"朗逸\",\"捷达\",\"迈腾\",\"高尔夫\",\"桑塔纳\",\"帕萨特\",\n",
    "          \"思域\",\"本田CR-V\",\"雅阁\",\n",
    "          \"雷凌\",\"威驰\",\"凯美瑞\",\"卡罗拉\",\n",
    "          \"轩逸\",\"天籁\",\n",
    "          \"福克斯\",\"福睿斯\",\"蒙迪欧\"]\n",
    "mod_names=[\"速腾\",\"迈腾\",\"雷凌\",\"卡罗拉\",\"凯美瑞\",\"天籁\",\"雅阁\",\"朗逸\",\n",
    "          \"威驰\",\"福克斯\",\"福睿斯\",\"蒙迪欧\",\"轩逸\",\"帕萨特\",\"途观\",\"飞度\",\"锋范\"]\n",
    "epochs=10\n",
    "nnn=len(mod_names)\n",
    "img_height=384\n",
    "img_width=512\n",
    "img_height=299\n",
    "img_width=299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "base_dir='/data/keras/download/qiche'\n",
    "train_dir=os.path.join(base_dir,'train')\n",
    "validation_dir=os.path.join(base_dir,'validation')\n",
    "test_dir=os.path.join(base_dir,'test')\n",
    "train_datagen=ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "     zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "#train_datagen=ImageDataGenerator(rescale=1./255)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height,img_width),\n",
    "    batch_size=10,\n",
    "    class_mode='categorical'   \n",
    ")\n",
    "\n",
    "validation_generator=test_datagen.flow_from_directory(   \n",
    "    validation_dir,\n",
    "    target_size=(img_height,img_width),\n",
    "    batch_size=5,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#contv_base=VGG16(weights='imagenet',include_top=False,input_shape=(img_height,img_width,3))\n",
    "# contv_base.summary()\n",
    "# contv_base.trainable=True\n",
    "# set_trainable=False\n",
    "# for layer in contv_base.layers:\n",
    "#     if layer.name=='block1_conv5':\n",
    "#         set_trainable=True\n",
    "#     if set_trainable:\n",
    "#         layer.trainable=True\n",
    "#     else:\n",
    "#         layer.trainable=False\n",
    "\n",
    "\n",
    "#contv_base=keras.applications.inception_resnet_v2.InceptionResNetV2(input_shape=(img_height,img_width,3))\n",
    "       \n",
    "\n",
    "# contv_base=xception.Xception(weights='imagenet',include_top=False,input_shape=(img_height,img_width,3))\n",
    "# contv_base.summary()\n",
    "# for layer in contv_base.layers:\n",
    "#      layer.trainable = False\n",
    "# for i, layer in enumerate(contv_base.layers):\n",
    "#     print(i, layer.name)\n",
    "\n",
    "\n",
    "# model=models.Sequential()\n",
    "# model.add(contv_base)\n",
    "# model.add(layers.Flatten())\n",
    "# #model.add(layers.Dropout(0.1))\n",
    "# model.add(layers.Dense(256,activation='relu'))\n",
    "# model.add(layers.Dense(nnn,activation='softmax'))\n",
    "# model.compile(loss='categorical_crossentropy',optimizer=optimizers.RMSprop(lr=1e-4),metrics=['acc'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history=model.fit_generator(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=train_generator.n/train_generator.batch_size,\n",
    "#     epochs=epochs,\n",
    "#     validation_data=validation_generator,\n",
    "#     validation_steps=validation_generator.n/validation_generator.batch_size\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in model.layers[:1]:\n",
    "#    layer.trainable = False\n",
    "# for layer in model.layers[1:]:\n",
    "#    layer.trainable = True\n",
    "# model.compile(loss='categorical_crossentropy',optimizer=optimizers.RMSprop(lr=1e-4),metrics=['acc'])\n",
    "# history=model.fit_generator(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=train_generator.n/train_generator.batch_size,\n",
    "#     epochs=epochs,\n",
    "#     validation_data=validation_generator,\n",
    "#     validation_steps=validation_generator.n/validation_generator.batch_size\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# 构建不带分类器的预训练模型\n",
    "base_model = xception.Xception(weights=\"imagenet\",include_top=False,input_shape=(img_height,img_width,3))\n",
    "\n",
    "# 添加全局平均池化层\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# 添加一个全连接层\n",
    "x = Dense(256, activation='relu')(x)\n",
    "\n",
    "# 添加一个分类器，假设我们有200个类\n",
    "predictions = Dense(nnn, activation='softmax')(x)\n",
    "\n",
    "# 构建我们需要训练的完整模型\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# 首先，我们只训练顶部的几层（随机初始化的层）\n",
    "# 锁住所有 InceptionV3 的卷积层\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 编译模型（一定要在锁层以后操作）\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=1e-3), loss='categorical_crossentropy',metrics=['acc'])\n",
    "\n",
    "# 在新的数据集上训练几代\n",
    "# history=model.fit_generator(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=train_generator.n/train_generator.batch_size,\n",
    "#     epochs=5,\n",
    "#     validation_data=validation_generator,\n",
    "#     validation_steps=validation_generator.n/validation_generator.batch_size\n",
    "# )\n",
    "\n",
    "# 现在顶层应该训练好了，让我们开始微调 Inception V3 的卷积层。\n",
    "# 我们会锁住底下的几层，然后训练其余的顶层。\n",
    "\n",
    "# 让我们看看每一层的名字和层号，看看我们应该锁多少层呢：\n",
    "# for i, layer in enumerate(base_model.layers):\n",
    "#    print(i, layer.name)\n",
    "\n",
    "# 我们选择训练最上面的两个 Inception block\n",
    "# 也就是说锁住前面249层，然后放开之后的层。\n",
    "# for layer in model.layers[:100]:\n",
    "#    layer.trainable = False\n",
    "for layer in model.layers[0:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# 我们需要重新编译模型，才能使上面的修改生效\n",
    "# 让我们设置一个很低的学习率，使用 SGD 来微调\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=1e-4), loss='categorical_crossentropy',metrics=['acc'])\n",
    "\n",
    "# 我们继续训练模型，这次我们训练最后两个 Inception block\n",
    "# 和两个全连接层\n",
    "history=model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n/train_generator.batch_size,\n",
    "    epochs=5,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.n/validation_generator.batch_size\n",
    ")\n",
    "time_t=time.strftime(\"%m%d%H%M\", time.localtime()) \n",
    "model.save('/data/keras/models/%s.h'%time_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n/train_generator.batch_size,\n",
    "    epochs=1,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.n/validation_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc=history.history['acc']\n",
    "val_acc=history.history['val_acc']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "epochs=range(1,len(acc)+1)\n",
    "plt.plot(epochs,acc,'bo',label='Training acc')\n",
    "plt.plot(epochs,val_acc,'b',label='Validation acc')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from mytool import MyTool\n",
    "test_imgs=['/data/keras/download/qiche/timg2.jpg',\n",
    "          '/data/keras/download/qiche/timg.jpg',\n",
    "          '/data/keras/download/qiche/su1.jpg',\n",
    "          '/data/keras/download/qiche/su2.jpg',\n",
    "          '/data/keras/download/qiche/su3.jpg',\n",
    "          '/data/test/su21.jpg',\n",
    "          '/data/test/su22.jpg',\n",
    "          '/data/test/su23.jpg',\n",
    "          '/data/test/su24.jpeg',\n",
    "          '/data/test/su25.jpeg',\n",
    "          '/data/test/su26.jpeg',\n",
    "           '/data/test/mt20.jpg',\n",
    "           '/data/test/mt21.jpg',\n",
    "           '/data/test/mt22.jpg',\n",
    "           '/data/test/mt23.jpg',\n",
    "           '/data/test/kll20.jpg',\n",
    "            '/data/test/kll21.jpg',\n",
    "            '/data/test/kll22.jpg',\n",
    "            '/data/test/kll23.jpg',\n",
    "            '/data/test/kll24.jpg',\n",
    "          ]\n",
    "\n",
    "for img_path in test_imgs:\n",
    "    #img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "    img =cv2.imread(img_path)\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()\n",
    "    img=MyTool.cro_img(img,img_height,img_width)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    x = image.img_to_array(img)\n",
    "    x=x/255\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    preds = model.predict(x)\n",
    "    paixu=dict(zip(train_generator.class_indices,preds[0]))\n",
    "    paixu= sorted(paixu.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(paixu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
