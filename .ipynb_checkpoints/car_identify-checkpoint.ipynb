{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,shutil,sys\n",
    "sys.path.append('/data/py/lib/') \n",
    "import keras\n",
    "import time\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.applications import VGG16\n",
    "from keras.applications import xception\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "####定义一些常用的训练调整参数###########\n",
    "epochs=5            #定义训练轮数\n",
    "batch_size=20       #每批数量\n",
    "lock_layer_num=0;   #锁住的层数\n",
    "lr=1e-4             #学习率\n",
    "dense_num=256       #连接层数量\n",
    "pre_train_epochs=1  #预训练轮数,0表示不进行预训练\n",
    "img_height=299      #训练图片高度\n",
    "img_width=299       #训练图片宽度\n",
    "is_load_model=False #是否加载自己训练的历史模型\n",
    "##########################\n",
    "\n",
    "base_dir='/data/keras/download/qiche'#汽车图片根目录\n",
    "train_dir=os.path.join(base_dir,'train')#汽车图片训练目录\n",
    "validation_dir=os.path.join(base_dir,'validation')#汽车图片验证目录\n",
    "test_dir=os.path.join(base_dir,'test')#汽车图片测试目录\n",
    "#精选一些品牌的汽车种类，引入更多的品牌的种类，不会大影响识别准确率，放心推广到更多的品牌和车型，\n",
    "#这里不演示更多的品牌，是因为我的显卡太烂了，图片太多，训练速度有点满\n",
    "mod_names=[\"速腾\",\"迈腾\",\"雷凌\",\"卡罗拉\",\"凯美瑞\",\n",
    "           \"天籁\",\"雅阁\",\"朗逸\",\"威驰\",\"福克斯\",\n",
    "           \"福睿斯\",\"蒙迪欧\",\"轩逸\",\"帕萨特\",\"途观\",\n",
    "           \"飞度\",\"锋范\"]\n",
    "\n",
    "mod_num=len(mod_names)#汽车车型总数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#使用图片数据增强，降低拟合的有效手段\n",
    "train_datagen=ImageDataGenerator(  \n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "#验证，测试数据不能进行数据增强\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height,img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'   \n",
    ")\n",
    "\n",
    "validation_generator=test_datagen.flow_from_directory(   \n",
    "    validation_dir,\n",
    "    target_size=(img_height,img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if is_load_model is False:\n",
    "    # 构建不带分类器的预训练模型\n",
    "    base_model = xception.Xception(weights=\"imagenet\",include_top=False,input_shape=(img_height,img_width,3))\n",
    "\n",
    "    # 添加全局平均池化层\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # 添加一个全连接层\n",
    "    x = Dense(dense_num, activation='relu')(x)\n",
    "\n",
    "    # 添加一个分类器\n",
    "    predictions = Dense(mod_num, activation='softmax')(x)\n",
    "\n",
    "    # 构建我们需要训练的完整模型\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # 锁住所有 Xception 的卷积层\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    #预训练\n",
    "    if pre_train_epochs>0:\n",
    "        model.compile(optimizer=optimizers.RMSprop(lr=1e-3), loss='categorical_crossentropy',metrics=['acc'])\n",
    "        history=model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=train_generator.n/train_generator.batch_size,\n",
    "            epochs=pre_train_epochs,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=validation_generator.n/validation_generator.batch_size\n",
    "        )\n",
    "\n",
    "    # 现在顶层应该训练好了，开始微调 Xception的卷积层。\n",
    "    # 锁住底下的几层，然后训练其余的顶层。\n",
    "    # 看看每一层的名字和层号，看看我们应该锁多少层呢：\n",
    "    # for i, layer in enumerate(base_model.layers):\n",
    "    #    print(i, layer.name)\n",
    "\n",
    "    # 锁住的层数\n",
    "    for layer in model.layers[:lock_layer_num]:\n",
    "       layer.trainable = False\n",
    "    for layer in model.layers[lock_layer_num:]:\n",
    "       layer.trainable = True\n",
    "\n",
    "    # 设置一个很低的学习率，使用 SGD 来微调\n",
    "    from keras.optimizers import SGD\n",
    "    model.compile(optimizer=optimizers.RMSprop(lr=lr), loss='categorical_crossentropy',metrics=['acc'])\n",
    "\n",
    "    # 继续训练模型\n",
    "    history=model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.n/train_generator.batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_generator.n/validation_generator.batch_size\n",
    "    )\n",
    "    #保存训练好的模型\n",
    "    time_t=time.strftime(\"%m%d%H%M\", time.localtime()) \n",
    "    model.save('/data/keras/models/%s.h'%time_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#显示训练过程中精度变化\n",
    "if is_load_model is False：\n",
    "    acc=history.history['acc']\n",
    "    val_acc=history.history['val_acc']\n",
    "    loss=history.history['loss']\n",
    "    val_loss=history.history['val_loss']\n",
    "    epochs=range(1,len(acc)+1)\n",
    "    plt.plot(epochs,acc,'bo',label='Training acc')\n",
    "    plt.plot(epochs,val_acc,'b',label='Validation acc')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#显示测试结果\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from mytool import MyTool\n",
    "test_imgs=['/data/keras/download/qiche/timg2.jpg',\n",
    "          '/data/keras/download/qiche/su1.jpg',\n",
    "          '/data/keras/download/qiche/su2.jpg',\n",
    "          '/data/keras/download/qiche/su3.jpg',\n",
    "          '/data/test/su21.jpg',\n",
    "          '/data/test/su22.jpg',\n",
    "          '/data/test/su23.jpg',\n",
    "          '/data/test/su24.jpeg',\n",
    "          '/data/test/su25.jpeg',\n",
    "          '/data/test/su26.jpeg',\n",
    "           '/data/test/mt20.jpg',\n",
    "           '/data/test/mt21.jpg',\n",
    "           '/data/test/mt22.jpg',\n",
    "           '/data/test/mt23.jpg',\n",
    "           '/data/test/kll20.jpg',\n",
    "            '/data/test/kll21.jpg',\n",
    "            '/data/test/kll22.jpg',\n",
    "            '/data/test/kll23.jpg',\n",
    "            '/data/test/kll24.jpg',\n",
    "          ]\n",
    "\n",
    "for img_path in test_imgs:\n",
    "    #img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "    img =cv2.imread(img_path)\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()\n",
    "    img=MyTool.cro_img(img,img_height,img_width)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    x = image.img_to_array(img)\n",
    "    x=x/255\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    preds = model.predict(x)\n",
    "    paixu=dict(zip(train_generator.class_indices,preds[0]))\n",
    "    paixu= sorted(paixu.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(paixu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contv_base=VGG16(weights='imagenet',include_top=False,input_shape=(img_height,img_width,3))\n",
    "# contv_base.summary()\n",
    "# contv_base.trainable=True\n",
    "# set_trainable=False\n",
    "# for layer in contv_base.layers:\n",
    "#     if layer.name=='block1_conv5':\n",
    "#         set_trainable=True\n",
    "#     if set_trainable:\n",
    "#         layer.trainable=True\n",
    "#     else:\n",
    "#         layer.trainable=False\n",
    "\n",
    "\n",
    "#contv_base=keras.applications.inception_resnet_v2.InceptionResNetV2(input_shape=(img_height,img_width,3))\n",
    "       \n",
    "\n",
    "# contv_base=xception.Xception(weights='imagenet',include_top=False,input_shape=(img_height,img_width,3))\n",
    "# contv_base.summary()\n",
    "# for layer in contv_base.layers:\n",
    "#      layer.trainable = False\n",
    "# for i, layer in enumerate(contv_base.layers):\n",
    "#     print(i, layer.name)\n",
    "\n",
    "\n",
    "# model=models.Sequential()\n",
    "# model.add(contv_base)\n",
    "# model.add(layers.Flatten())\n",
    "# #model.add(layers.Dropout(0.1))\n",
    "# model.add(layers.Dense(256,activation='relu'))\n",
    "# model.add(layers.Dense(mod_num,activation='softmax'))\n",
    "# model.compile(loss='categorical_crossentropy',optimizer=optimizers.RMSprop(lr=1e-4),metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
